{% extends "base.html" %} {% load static %} {% block title %}my-megalith{%
endblock %} {% block content %}
<h1>What is a megalith?</h1>
<p>
  Megalith is a term I made up to describe the single encompassing architecture
  I use to deploy my personal projects. The architecture is a manifestation of
  <a href="https://thatcherthornberry.com/posts/efficiency"
    >my deep-seated obsession with efficiency</a
  >.
</p>
<h2>Overview</h2>
<p>
  The purpose of this architecture is optimize the tradeoff between development
  time, deployment complexity, and cost. All of my projects live under the
  domain thatcherthornberry.com. The core of each project lives in its own,
  isolated docker container, but tend to share some resources with other
  projects such as databases.
</p>
<h2>Source Control</h2>
<p>
  Each project lives in its own repository, for example
  <a href="https://github.com/thatchert/spotifly">QSongs</a>. The
  <a href="https://gihub.com/thatchert/thatcherthornberry"
    >megalith repository</a
  >
  pulls each project into its repository using a technology called
  <a href="https://www.atlassian.com/git/tutorials/git-subtree">git subtree</a>.
  This technique allows me to keep each project separate but also keep the
  deployment process consolidated to a single repository.
</p>
<h3>GitHub Actions</h3>
<p>
  GitHub actions is my tool of choice for CI/CD because of its convenience. If
  you have a GitHub repository, GitHub actions can be implemented with minimal
  changes to your codebase.
</p>
<p>
  For each new project, I add a simple script to
  <code>.github/workflows</code> which sends a
  <a
    href="https://docs.github.com/en/actions/reference/events-that-trigger-workflows#repository_dispatch"
    >repository dispatch</a
  >
  event to the megalith repository. The megalith repository then pulls the
  latest changes from the project repository and merges it with its own git
  history.
</p>
<p>
  In the megalith repository, I have a CI/CD pipeline waiting for changes to be
  pushed to the master branch. Consequently, when I make a change to the
  megalith itself, or a sub repository, the CI/CD pipeline is triggered and the
  changes are deployed to the production server.
</p>
<h2>DNS</h2>
<p>
  I registered thatcherthornberry.com with
  <a href="https://domains.google.com">Google</a>. There are (at least) two
  parts to every domain name: the second-level domain (thatcherthornberry) and
  the top-level domain (com). Google is a registrar, which means they manage the
  second-level domain. All top-level domains are managed by
  <a href="https://www.icann.org/">ICANN</a>, which is a non-profit organization
  that manages the internet's domain name system. ICANN delegates management of
  specific top-level domains to different organizations. For instance, the U.S.
  based company VeriSign manages the .com and .net top-level domains.
</p>
<p>
  After registering a domain, I pay Google $12 per year to keep it. However,
  this payment is split among the various organizations. Here is a made up
  <a
    href="https://webmasters.stackexchange.com/questions/61467/if-icann-only-charges-18%c2%a2-per-domain-name-why-am-i-paying-10?newreg=68106e778e23493a829a5861411ad722"
    >example of the breakdown</a
  >:
</p>
<ul>
  <li>$0.18 to ICANN</li>
  <li>$8.85 to Verisign</li>
  <li>$0.30 to a credit card processor</li>
  <li>$2.67 to Google</li>
</ul>
<h3>SSL</h3>
<p>
  Once you've registered a domain, you have permission to use it. However, steps
  remain to serve content over your domain securely. Secure Sockets Layer (SSL)
  is a protocol to secure communications over the internet. I'll add more
  information to this section in the future. For now, I'll just say that I use
  <a href="https://letsencrypt.org/">Let's Encrypt</a> to generate SSL
  certificates for my domains. A Docker container runs a client to interface
  with the Let's Encrypt Certificate Authority to generate a wildcard
  certificate for thatcherthornberry.com. The certificate is valid for all
  subdomains of thatcherthornberry.com. Thus, allowing me to serve content over
  https for an domain under my website such as
  <a href="https://qsongs.thatcherthornberry.com"
    >https://qsongs.thatcherthornberry.com</a
  >. and
  <a href="https://blog.thatcherthornberry.com"
    >https://blog.thatcherthornberry.com</a
  >.
</p>
<h2>Nginx</h2>
<p>
  In the name of cost efficiency, I host all of my projects on a single e2-micro
  VM from Google for $3 per month. Within Google's domain management service, I
  created a few rules to route all traffic to thatcherthornberry.com or
  *.thatcherthornberry.com to the VM. Nginx receives all requests to port 80 and
  443 (http and https, it forwards http request to the SSL port 443). When it
  receives a request, it checks the host header to determine which project to
  serve. Thus, a request to
  <a href="https://qsongs.thatcherthornberry.com"
    >https://qsongs.thatcherthornberry.com</a
  >
  will be routed to the Docker container hosting the QSongs project. Once it
  hits that container, the request is handled by the container's logic
  (typically a Gunicorn web server serving a Django project).
</p>
<p>
  Additionally, Nginx is configured to serve static files directly from the file
  system. This is handy because Gunicorn is not optimized to serve static files.
</p>
<h2>Docker</h2>
<p>
  Docker is one of my favorite technologies. It allows isolated environments to
  coexist on a single host.
</p>
<p>
  As mentioned, the core of each project lives in its own Docker container.
  Nginx forwards requests to the appropriate container and the project can
  handle that request however it needs to.
</p>
<p>
  Although the core of each project is isolated, to save resources, projects
  often share resources with eachother. For instance, many of my projects use
  PostgreSQL as a database. A single container runs a PostgreSQL server and all
  projects connect to that server and use their own isolated Database.
</p>
<h3>Docker Compose</h3>
<p>
  Docker Compose is a simple tool for container orchestration. All it really
  does is allow you to define a set of containers and their dependencies in a
  single file and deploy them with a single command.
</p>
<p>
  To deploy all of my projects and there containers, I need to create a single
  docker-compose.yaml file which holds the configuration for each project. In
  the past, I would have to manually create this file. Recently, I created an
  aggregator which pulls the docker-compose file for each project and merges
  them into a single file.
</p>
<h2>Problems, the Future</h2>
<p>
  This megalith architecture has served me well for almost 2 years. Thus I've
  had time to identify some insatisfactory aspects of the architecture.
</p>
<h3>Git Subtree Issues</h3>
<p>
  The biggest gripe I have with Git Subtree is its instability. While making
  changes in the megalith repository, I have to be very careful not to make
  changes to any files that belong to a subtree as this will cause major
  conflicts.
</p>
<p>
  Additionally, I haven't put the time in to automating the process of creating
  git subtrees within the megalith. So, each time I'd like to deploy a new
  project to my site, I have to manually create a git subtree. Although this is
  a simple process, it is not maximally efficient.
</p>
<p>I haven't yet landed on a potential solution.</p>
<h3>Nginx Issues</h3>
<p>
  Unlike Docker Compose, I've failed to create an aggregator for Nginx. Thus,
  each time I deploy a new project, I have to manually add a new server block to
  the Nginx configuration. Once I find the motivation, I'll create an aggregator
  for these .conf files.
</p>
{% endblock %}
